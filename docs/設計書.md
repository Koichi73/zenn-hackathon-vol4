# 基本設計

## MVP機能要件
- 作成者
    - 動画をアップロードする
    - 動画から手順ごとのテキストを生成する
    - 動画から手順ごとの画像を切り抜く
    - 画像内の個人情報をマスクする
    - 画像内のボタンを赤枠で強調する
    - AIの出力を手動で変更する
    - 作成者権限でログインする
    - 編集モードとプレビューモードがある
    - 利用者が指摘した箇所を確認する
    - 利用者に手順書を共有する(URLでの共有)
    - 手順書をPDFでダウンロードする(開発せずに印刷機能を使う)
- 利用者
    - 手順書を閲覧できる(要検討: ログインなしもしくは閲覧権限でのログイン)
    - 手順書の古い箇所を1クリックで指摘する
        - TeamsやSlackのスタンプorYoutubeの低評価ボタンみたいなイメージ
    - 指摘の際にコメントを残す


## 非MVP機能要件
- 作成者
    - 追加の動画で部分的な差分をとる
    - 入力動画が綺麗ではない時の対応
        - 動画内で間違った手順が含まれてる、手戻りがある、など
    - 手順書と動画のシンクロ
        - テキストや切り出し画像をクリックすると動画がその位置に飛ぶ
        - 動画のシークバーを動かすと手順書の該当箇所に飛ぶ
- 利用者
    - 他人の指摘の履歴を確認する
        - 要検討: MVPに入れてもいいかも


## 技術スタック
- バックエンド
    - フレームワーク: FastAPI
    - AI: Vertex AI (Gemini 3)
        - 動画などのマルチモーダルに強い
    - Agentフレームワーク: ADK
    - 画像処理: ffmpeg
- フロントエンド
    - フレームワーク: Next.js
    - UI: TailwindCSS
    - Canvas: react-konva
    - 動画アップロード: Firebase SDK
        - サーバを経由せず直接アップロードする
- データベース
    - Firestore
        - テキストやユーザー情報など
        - 動画はCloud StrageのURLとして保存する
    - Cloud Storage
        - 動画と画像(これらはFirestoreだと大きすぎる)
        - GeminiはCloud Strageの動画を解析できる
        - 動画 → フロント → Cloud Storage → Gemini の流れ
- デプロイ 
    - フロントエンド: Cloud Run もしくは Firebase Hosting
        - Cloud Run: 
            - 統一感ある
            - Dockerfile書くのは問題ない
            - デブロイが遅い
        - Firebase Hosting: 
            - デプロイが速い
            - 裏でCloud Runを使ってる
            - デメリットはあまりない
    - バックエンド: Cloud Run


## アーキテクチャ図(MVP)

```mermaid
graph LR
    User((User))
    
    subgraph Frontend ["Frontend (Cloud Run / Firebase Hosting)"]
        NextJS["Next.js App<br/>(Firebase SDK)"]
    end

    subgraph Google_Cloud ["Google Cloud Platform"]
        subgraph Backend ["Backend (Cloud Run)"]
            FastAPI[FastAPI Server]
            ADK[ADK Agent Logic]
        end
        
        Storage["Cloud Storage (GCS)"]
        DB[(Firestore)]
        Gemini["Vertex AI (Gemini 3)"]
    end

    %% 詳細なフロー
    User -- 1. 動画選択 & UP --> NextJS
    NextJS -- 2. 直接アップロード<br/>(Server経由せず) --> Storage
    NextJS -- 3. 解析リクエスト<br/>(動画パスを送信) --> FastAPI
    FastAPI -- 4. 動画URI参照 --> Gemini
    Gemini -- 5. 手順テキスト --> FastAPI
    FastAPI -- 6. 保存 --> DB
    FastAPI -- 7. 完了通知 --> NextJS
```


## アーキテクチャ図(ストリーミング)

```mermaid
sequenceDiagram
    participant U as User
    participant FE as Next.js (UI)
    participant BE as FastAPI
    participant AI as Gemini
    participant DB as Firestore

    U->>FE: 動画アップロード
    FE->>BE: 解析リクエスト
    
    rect rgb(230, 240, 255)
        Note over BE, AI: Phase 1: 構造解析 (数秒)
        BE->>AI: 動画全体からタイトル/時間抽出
        AI-->>BE: ステップリスト (JSON)
    end

    BE->>DB: 初期データ保存 (タイトルのみ)
    BE-->>FE: 200 OK (処理開始)
    
    Note right of FE: ユーザーには「5つの手順を検出しました...」<br/>とスケルトンを表示

    loop 各ステップごとに実行 (Background)
        BE->>BE: 画像切り抜き (ffmpeg)
        BE->>AI: 画像解析 (Phase 3)
        AI-->>BE: マスク位置・説明文
        BE->>DB: update() 特定のステップを更新
        DB-->>FE: onSnapshot (リアルタイム反映)
        Note right of FE: 1つずつ画像と説明が<br/>UIにポコポコ表示される
    end
```


## ページ構成
```
/
├── /login          # ログイン画面
├── /dashboard      # ダッシュボード (一覧表示、フィードバック通知、アップロード)
├── /editor/[id]    # 編集画面
└── /share/[id]     # 手順書閲覧画面
```
